<?xml version='1.0' encoding='UTF-8'?>

<bag xmlns:boolean="http://www.w3.org/2001/XMLSchema#boolean" xmlns:float="http://www.w3.org/2001/XMLSchema#float" xmlns:int="http://www.w3.org/2001/XMLSchema#int" xmlns:unsignedInt="http://www.w3.org/2001/XMLSchema#unsignedInt" xmlns:unsignedLong="http://www.w3.org/2001/XMLSchema#unsignedLong" int:version="9">
 <issues>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>6</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>8</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_serialized_user_function</id>
   <int:severity>3</int:severity>
   <text>User-defined functions in the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;loop body&lt;/a&gt; are not vectorized. </text>
   <title>Serialized user function call(s) present </title>
   <attributes>
    <float:severity>3</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>3</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_serialized_user_function_try_simd_c</id>
     <text>Some user-defined function(s) are not vectorized or inlined by the compiler. To fix: Do one of the following: &lt;ul&gt; &lt;li&gt; Enforce vectorization of the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; by means of SIMD instructions and/or create a SIMD version of the function(s) using a &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;directive&lt;/a&gt;: &lt;table&gt; &lt;tr&gt; &lt;th&gt; Target &lt;/th&gt; &lt;th&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Source Loop &lt;/td&gt; &lt;td&gt; #pragma simd or #pragma omp simd &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Inner function definition or declaration &lt;/td&gt; &lt;td&gt; #pragma omp declare simd &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;li&gt; If using the &lt;div class=&quot;inplace_sample&quot;&gt;Ob&lt;/div&gt; or &lt;div class=&quot;inplace_sample&quot;&gt;inline-level&lt;/div&gt; compiler option to control inline expansion with the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument, use an &lt;div class=&quot;inplace_sample&quot;&gt;inline&lt;/div&gt; keyword to enable inlining or replace the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument with &lt;div class=&quot;inplace_sample&quot;&gt;2&lt;/div&gt; to enable inlining of any function at compiler discretion. &lt;/ul&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.htm&quot;&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-B847FED8-4D82-4250-A241-8755134F210F.htm&quot;&gt;omp declare simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.htm&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/getting-started-with-intel-composer-xe-2013-compiler-pragmas-and-directives&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; and &lt;a href=&quot;https://software.intel.com/en-us/vectorization-resources-advisor&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Vectorize serialized function(s) inside loop </title>
     <attributes>
      <float:confidence>3</float:confidence>
     </attributes>
     <parameters>
      <user_functions arrayOf="item">
       <item>func@0x1400fd434</item>
       <item>func@0x1401036b3</item>
      </user_functions>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>9</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>10</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_serialized_user_function</id>
   <int:severity>3</int:severity>
   <text>User-defined functions in the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;loop body&lt;/a&gt; are not vectorized. </text>
   <title>Serialized user function call(s) present </title>
   <attributes>
    <float:severity>3</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>3</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_serialized_user_function_try_simd_c</id>
     <text>Some user-defined function(s) are not vectorized or inlined by the compiler. To fix: Do one of the following: &lt;ul&gt; &lt;li&gt; Enforce vectorization of the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; by means of SIMD instructions and/or create a SIMD version of the function(s) using a &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;directive&lt;/a&gt;: &lt;table&gt; &lt;tr&gt; &lt;th&gt; Target &lt;/th&gt; &lt;th&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Source Loop &lt;/td&gt; &lt;td&gt; #pragma simd or #pragma omp simd &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Inner function definition or declaration &lt;/td&gt; &lt;td&gt; #pragma omp declare simd &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;li&gt; If using the &lt;div class=&quot;inplace_sample&quot;&gt;Ob&lt;/div&gt; or &lt;div class=&quot;inplace_sample&quot;&gt;inline-level&lt;/div&gt; compiler option to control inline expansion with the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument, use an &lt;div class=&quot;inplace_sample&quot;&gt;inline&lt;/div&gt; keyword to enable inlining or replace the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument with &lt;div class=&quot;inplace_sample&quot;&gt;2&lt;/div&gt; to enable inlining of any function at compiler discretion. &lt;/ul&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.htm&quot;&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-B847FED8-4D82-4250-A241-8755134F210F.htm&quot;&gt;omp declare simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.htm&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/getting-started-with-intel-composer-xe-2013-compiler-pragmas-and-directives&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; and &lt;a href=&quot;https://software.intel.com/en-us/vectorization-resources-advisor&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Vectorize serialized function(s) inside loop </title>
     <attributes>
      <float:confidence>3</float:confidence>
     </attributes>
     <parameters>
      <user_functions arrayOf="item">
       <item>func@0x1400fd430</item>
       <item>func@0x1400fd434</item>
       <item>func@0x1401036b3</item>
      </user_functions>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>12</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_loop_misalignment</id>
   <int:severity>1</int:severity>
   <text>Align this loop using compiler options or pragmas</text>
   <title>Misaligned loop code present</title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_align_loop_c</id>
     <text>align_loop_text</text>
     <title>Force the compiler to align loop code </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>13</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>21</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_serialized_user_function</id>
   <int:severity>3</int:severity>
   <text>User-defined functions in the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;loop body&lt;/a&gt; are not vectorized. </text>
   <title>Serialized user function call(s) present </title>
   <attributes>
    <float:severity>3</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>3</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_serialized_user_function_try_simd_c</id>
     <text>Some user-defined function(s) are not vectorized or inlined by the compiler. To fix: Do one of the following: &lt;ul&gt; &lt;li&gt; Enforce vectorization of the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; by means of SIMD instructions and/or create a SIMD version of the function(s) using a &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;directive&lt;/a&gt;: &lt;table&gt; &lt;tr&gt; &lt;th&gt; Target &lt;/th&gt; &lt;th&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Source Loop &lt;/td&gt; &lt;td&gt; #pragma simd or #pragma omp simd &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Inner function definition or declaration &lt;/td&gt; &lt;td&gt; #pragma omp declare simd &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;li&gt; If using the &lt;div class=&quot;inplace_sample&quot;&gt;Ob&lt;/div&gt; or &lt;div class=&quot;inplace_sample&quot;&gt;inline-level&lt;/div&gt; compiler option to control inline expansion with the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument, use an &lt;div class=&quot;inplace_sample&quot;&gt;inline&lt;/div&gt; keyword to enable inlining or replace the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument with &lt;div class=&quot;inplace_sample&quot;&gt;2&lt;/div&gt; to enable inlining of any function at compiler discretion. &lt;/ul&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.htm&quot;&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-B847FED8-4D82-4250-A241-8755134F210F.htm&quot;&gt;omp declare simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.htm&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/getting-started-with-intel-composer-xe-2013-compiler-pragmas-and-directives&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; and &lt;a href=&quot;https://software.intel.com/en-us/vectorization-resources-advisor&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Vectorize serialized function(s) inside loop </title>
     <attributes>
      <float:confidence>3</float:confidence>
     </attributes>
     <parameters>
      <user_functions arrayOf="item">
       <item>func@0x1401036b3</item>
      </user_functions>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>22</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>24</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_serialized_user_function</id>
   <int:severity>3</int:severity>
   <text>User-defined functions in the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;loop body&lt;/a&gt; are not vectorized. </text>
   <title>Serialized user function call(s) present </title>
   <attributes>
    <float:severity>3</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>3</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_serialized_user_function_try_simd_c</id>
     <text>Some user-defined function(s) are not vectorized or inlined by the compiler. To fix: Do one of the following: &lt;ul&gt; &lt;li&gt; Enforce vectorization of the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; by means of SIMD instructions and/or create a SIMD version of the function(s) using a &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;directive&lt;/a&gt;: &lt;table&gt; &lt;tr&gt; &lt;th&gt; Target &lt;/th&gt; &lt;th&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Source Loop &lt;/td&gt; &lt;td&gt; #pragma simd or #pragma omp simd &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Inner function definition or declaration &lt;/td&gt; &lt;td&gt; #pragma omp declare simd &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;li&gt; If using the &lt;div class=&quot;inplace_sample&quot;&gt;Ob&lt;/div&gt; or &lt;div class=&quot;inplace_sample&quot;&gt;inline-level&lt;/div&gt; compiler option to control inline expansion with the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument, use an &lt;div class=&quot;inplace_sample&quot;&gt;inline&lt;/div&gt; keyword to enable inlining or replace the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument with &lt;div class=&quot;inplace_sample&quot;&gt;2&lt;/div&gt; to enable inlining of any function at compiler discretion. &lt;/ul&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.htm&quot;&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-B847FED8-4D82-4250-A241-8755134F210F.htm&quot;&gt;omp declare simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.htm&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/getting-started-with-intel-composer-xe-2013-compiler-pragmas-and-directives&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; and &lt;a href=&quot;https://software.intel.com/en-us/vectorization-resources-advisor&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Vectorize serialized function(s) inside loop </title>
     <attributes>
      <float:confidence>3</float:confidence>
     </attributes>
     <parameters>
      <user_functions arrayOf="item">
       <item>func@0x14008c5d0</item>
      </user_functions>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>38</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_indirect_call</id>
   <int:severity>1</int:severity>
   <text>Indirect function call(s) in the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;loop body&lt;/a&gt; are preventing the compiler from vectorizing the loop. &lt;br&gt; Indirect calls, sometimes called &lt;em&gt;indirect jumps&lt;/em&gt;, get the callee address from a register or memory; direct calls get the callee address from an argument. Even if you force loop vectorization, indirect calls remain serialized. </text>
   <title>Indirect function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_indirect_call_move_c</id>
     <text>Indirect function or subroutine calls cannot be vectorized. To fix: Avoid using indirect calls in loops. </text>
     <title>Remove indirect call(s) inside loop </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>38</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_serialized_user_function</id>
   <int:severity>3</int:severity>
   <text>User-defined functions in the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;loop body&lt;/a&gt; are not vectorized. </text>
   <title>Serialized user function call(s) present </title>
   <attributes>
    <float:severity>3</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>3</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_serialized_user_function_try_simd_c</id>
     <text>Some user-defined function(s) are not vectorized or inlined by the compiler. To fix: Do one of the following: &lt;ul&gt; &lt;li&gt; Enforce vectorization of the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; by means of SIMD instructions and/or create a SIMD version of the function(s) using a &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;directive&lt;/a&gt;: &lt;table&gt; &lt;tr&gt; &lt;th&gt; Target &lt;/th&gt; &lt;th&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Source Loop &lt;/td&gt; &lt;td&gt; #pragma simd or #pragma omp simd &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Inner function definition or declaration &lt;/td&gt; &lt;td&gt; #pragma omp declare simd &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;li&gt; If using the &lt;div class=&quot;inplace_sample&quot;&gt;Ob&lt;/div&gt; or &lt;div class=&quot;inplace_sample&quot;&gt;inline-level&lt;/div&gt; compiler option to control inline expansion with the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument, use an &lt;div class=&quot;inplace_sample&quot;&gt;inline&lt;/div&gt; keyword to enable inlining or replace the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument with &lt;div class=&quot;inplace_sample&quot;&gt;2&lt;/div&gt; to enable inlining of any function at compiler discretion. &lt;/ul&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.htm&quot;&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-B847FED8-4D82-4250-A241-8755134F210F.htm&quot;&gt;omp declare simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.htm&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/getting-started-with-intel-composer-xe-2013-compiler-pragmas-and-directives&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; and &lt;a href=&quot;https://software.intel.com/en-us/vectorization-resources-advisor&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Vectorize serialized function(s) inside loop </title>
     <attributes>
      <float:confidence>3</float:confidence>
     </attributes>
     <parameters>
      <user_functions arrayOf="item">
       <item>func@0x1400fd3a0</item>
       <item>func@0x14010167d</item>
      </user_functions>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>51</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>54</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_serialized_user_function</id>
   <int:severity>3</int:severity>
   <text>User-defined functions in the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;loop body&lt;/a&gt; are not vectorized. </text>
   <title>Serialized user function call(s) present </title>
   <attributes>
    <float:severity>3</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>3</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_serialized_user_function_try_simd_c</id>
     <text>Some user-defined function(s) are not vectorized or inlined by the compiler. To fix: Do one of the following: &lt;ul&gt; &lt;li&gt; Enforce vectorization of the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; by means of SIMD instructions and/or create a SIMD version of the function(s) using a &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;directive&lt;/a&gt;: &lt;table&gt; &lt;tr&gt; &lt;th&gt; Target &lt;/th&gt; &lt;th&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Source Loop &lt;/td&gt; &lt;td&gt; #pragma simd or #pragma omp simd &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Inner function definition or declaration &lt;/td&gt; &lt;td&gt; #pragma omp declare simd &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;li&gt; If using the &lt;div class=&quot;inplace_sample&quot;&gt;Ob&lt;/div&gt; or &lt;div class=&quot;inplace_sample&quot;&gt;inline-level&lt;/div&gt; compiler option to control inline expansion with the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument, use an &lt;div class=&quot;inplace_sample&quot;&gt;inline&lt;/div&gt; keyword to enable inlining or replace the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument with &lt;div class=&quot;inplace_sample&quot;&gt;2&lt;/div&gt; to enable inlining of any function at compiler discretion. &lt;/ul&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.htm&quot;&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-B847FED8-4D82-4250-A241-8755134F210F.htm&quot;&gt;omp declare simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.htm&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/getting-started-with-intel-composer-xe-2013-compiler-pragmas-and-directives&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; and &lt;a href=&quot;https://software.intel.com/en-us/vectorization-resources-advisor&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Vectorize serialized function(s) inside loop </title>
     <attributes>
      <float:confidence>3</float:confidence>
     </attributes>
     <parameters>
      <user_functions arrayOf="item">
       <item>func@0x1400fd3a0</item>
       <item>func@0x14010167d</item>
      </user_functions>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>55</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_loop_misalignment</id>
   <int:severity>1</int:severity>
   <text>Align this loop using compiler options or pragmas</text>
   <title>Misaligned loop code present</title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_align_loop_c</id>
     <text>align_loop_text</text>
     <title>Force the compiler to align loop code </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>63</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>66</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_serialized_user_function</id>
   <int:severity>3</int:severity>
   <text>User-defined functions in the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;loop body&lt;/a&gt; are not vectorized. </text>
   <title>Serialized user function call(s) present </title>
   <attributes>
    <float:severity>3</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>3</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_serialized_user_function_try_simd_c</id>
     <text>Some user-defined function(s) are not vectorized or inlined by the compiler. To fix: Do one of the following: &lt;ul&gt; &lt;li&gt; Enforce vectorization of the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; by means of SIMD instructions and/or create a SIMD version of the function(s) using a &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;directive&lt;/a&gt;: &lt;table&gt; &lt;tr&gt; &lt;th&gt; Target &lt;/th&gt; &lt;th&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Source Loop &lt;/td&gt; &lt;td&gt; #pragma simd or #pragma omp simd &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Inner function definition or declaration &lt;/td&gt; &lt;td&gt; #pragma omp declare simd &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;li&gt; If using the &lt;div class=&quot;inplace_sample&quot;&gt;Ob&lt;/div&gt; or &lt;div class=&quot;inplace_sample&quot;&gt;inline-level&lt;/div&gt; compiler option to control inline expansion with the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument, use an &lt;div class=&quot;inplace_sample&quot;&gt;inline&lt;/div&gt; keyword to enable inlining or replace the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument with &lt;div class=&quot;inplace_sample&quot;&gt;2&lt;/div&gt; to enable inlining of any function at compiler discretion. &lt;/ul&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.htm&quot;&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-B847FED8-4D82-4250-A241-8755134F210F.htm&quot;&gt;omp declare simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.htm&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/getting-started-with-intel-composer-xe-2013-compiler-pragmas-and-directives&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; and &lt;a href=&quot;https://software.intel.com/en-us/vectorization-resources-advisor&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Vectorize serialized function(s) inside loop </title>
     <attributes>
      <float:confidence>3</float:confidence>
     </attributes>
     <parameters>
      <user_functions arrayOf="item">
       <item>func@0x1401036b3</item>
      </user_functions>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>67</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>68</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>69</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>70</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>79</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>86</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_serialized_user_function</id>
   <int:severity>3</int:severity>
   <text>User-defined functions in the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;loop body&lt;/a&gt; are not vectorized. </text>
   <title>Serialized user function call(s) present </title>
   <attributes>
    <float:severity>3</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>3</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_serialized_user_function_try_simd_c</id>
     <text>Some user-defined function(s) are not vectorized or inlined by the compiler. To fix: Do one of the following: &lt;ul&gt; &lt;li&gt; Enforce vectorization of the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; by means of SIMD instructions and/or create a SIMD version of the function(s) using a &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;directive&lt;/a&gt;: &lt;table&gt; &lt;tr&gt; &lt;th&gt; Target &lt;/th&gt; &lt;th&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Source Loop &lt;/td&gt; &lt;td&gt; #pragma simd or #pragma omp simd &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Inner function definition or declaration &lt;/td&gt; &lt;td&gt; #pragma omp declare simd &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;li&gt; If using the &lt;div class=&quot;inplace_sample&quot;&gt;Ob&lt;/div&gt; or &lt;div class=&quot;inplace_sample&quot;&gt;inline-level&lt;/div&gt; compiler option to control inline expansion with the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument, use an &lt;div class=&quot;inplace_sample&quot;&gt;inline&lt;/div&gt; keyword to enable inlining or replace the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument with &lt;div class=&quot;inplace_sample&quot;&gt;2&lt;/div&gt; to enable inlining of any function at compiler discretion. &lt;/ul&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.htm&quot;&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-B847FED8-4D82-4250-A241-8755134F210F.htm&quot;&gt;omp declare simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.htm&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/getting-started-with-intel-composer-xe-2013-compiler-pragmas-and-directives&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; and &lt;a href=&quot;https://software.intel.com/en-us/vectorization-resources-advisor&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Vectorize serialized function(s) inside loop </title>
     <attributes>
      <float:confidence>3</float:confidence>
     </attributes>
     <parameters>
      <user_functions arrayOf="item">
       <item>func@0x1400e42f0</item>
       <item>func@0x1400e42f4</item>
       <item>func@0x1400e613a</item>
       <item>func@0x1400e61d4</item>
      </user_functions>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>90</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_register_pressure</id>
   <int:severity>3</int:severity>
   <text>Possible register &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;spilling&lt;/a&gt; was detected and all vector registers are in use. This may negatively impact performance, because the spilled variable must be loaded to and unloaded from main memory. Improve performance by decreasing vector &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;register pressure&lt;/a&gt;. </text>
   <title>Vector register spilling possible </title>
   <attributes>
    <float:severity>3</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>3</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_registers_pressure_split_loop_c</id>
     <text>Possible register &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;spilling&lt;/a&gt; along with high vector &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;register pressure&lt;/a&gt; is preventing effective vectorization. To fix: Use a &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;directive&lt;/a&gt; or rewrite your code to distribute the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt;. This can decrease register pressure as well as enable software pipelining and improve both instruction and data cache use. &lt;/br&gt; &lt;table&gt; &lt;tr&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;ICL/ICC/ICPC&lt;/a&gt; Directive &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;IFORT&lt;/a&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; #pragma distribute_point &lt;/td&gt; &lt;td&gt; !DIR$ DISTRIBUTE POINT &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;C++&lt;/strong&gt;: &lt;a href=&quot;C++/17/index.htm#GUID-03B94EAB-70E2-4B45-B275-D73FD76961A0.htm&quot;&gt;distribute_point&lt;/a&gt;&lt;!--, &lt;a href=&quot;https://software.intel.com/en-us/compiler_16.0_ug_c&quot;&gt;Intel&amp;reg; C++ Compiler XE 16.0 User and Reference Guides&lt;/a&gt;--&gt; &lt;li&gt;&lt;strong&gt;Fortran&lt;/strong&gt;: &lt;a href=&quot;Fortran/17/index.htm#GUID-759F460A-1FF1-44AC-B64C-910D8C57BB1B.htm&quot;&gt;DISTRIBUTE POINT&lt;/a&gt;&lt;!--, &lt;a href=&quot;https://software.intel.com/en-us/compiler_16.0_ug_f&quot;&gt;Intel&amp;reg; Fortran Compiler XE 16.0 User and Reference Guides&lt;/a&gt;--&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/getting-started-with-intel-composer-xe-2013-compiler-pragmas-and-directives&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/3d-finite-differences-on-multi-core-processors&quot;&gt;3D Finite Differences on Multi-core Processors&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Split loop into smaller loops </title>
     <attributes>
      <float:confidence>3</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>90</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_div</id>
   <int:severity>1</int:severity>
   <text>div_issue_text</text>
   <title>Unoptimized floating point operation processing possible</title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_div_c</id>
     <text>add_div_text</text>
     <title>Enable the use of approximate division instructions </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_sqrt_c</id>
     <text>add_sqrt_text</text>
     <title>Enable the use of approximate sqrt instructions </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>90</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>90</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>91</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>97</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_serialized_user_function</id>
   <int:severity>3</int:severity>
   <text>User-defined functions in the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;loop body&lt;/a&gt; are not vectorized. </text>
   <title>Serialized user function call(s) present </title>
   <attributes>
    <float:severity>3</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>3</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_serialized_user_function_try_simd_c</id>
     <text>Some user-defined function(s) are not vectorized or inlined by the compiler. To fix: Do one of the following: &lt;ul&gt; &lt;li&gt; Enforce vectorization of the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; by means of SIMD instructions and/or create a SIMD version of the function(s) using a &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;directive&lt;/a&gt;: &lt;table&gt; &lt;tr&gt; &lt;th&gt; Target &lt;/th&gt; &lt;th&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Source Loop &lt;/td&gt; &lt;td&gt; #pragma simd or #pragma omp simd &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; Inner function definition or declaration &lt;/td&gt; &lt;td&gt; #pragma omp declare simd &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;li&gt; If using the &lt;div class=&quot;inplace_sample&quot;&gt;Ob&lt;/div&gt; or &lt;div class=&quot;inplace_sample&quot;&gt;inline-level&lt;/div&gt; compiler option to control inline expansion with the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument, use an &lt;div class=&quot;inplace_sample&quot;&gt;inline&lt;/div&gt; keyword to enable inlining or replace the &lt;div class=&quot;inplace_sample&quot;&gt;1&lt;/div&gt; argument with &lt;div class=&quot;inplace_sample&quot;&gt;2&lt;/div&gt; to enable inlining of any function at compiler discretion. &lt;/ul&gt; &lt;b&gt;Read More:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.htm&quot;&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-B847FED8-4D82-4250-A241-8755134F210F.htm&quot;&gt;omp declare simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.htm&quot;&gt;simd&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/getting-started-with-intel-composer-xe-2013-compiler-pragmas-and-directives&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; and &lt;a href=&quot;https://software.intel.com/en-us/vectorization-resources-advisor&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Vectorize serialized function(s) inside loop </title>
     <attributes>
      <float:confidence>3</float:confidence>
     </attributes>
     <parameters>
      <user_functions arrayOf="item">
       <item>func@0x1400fd1e0</item>
       <item>func@0x1400fe9a4</item>
       <item>func@0x140104684</item>
      </user_functions>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>112</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>69</unsignedInt:flags>
   <id>issue_check_access_patterns</id>
   <int:severity>2</int:severity>
   <text>Inefficient memory access patterns may result in significant vector code execution slowdown or block automatic vectorization by the compiler. Improve performance by investigating. </text>
   <title>Possible inefficient memory access patterns present </title>
   <attributes>
    <float:severity>2</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>2</int:confidence>
     <unsignedInt:flags>1032</unsignedInt:flags>
     <id>rec_check_access_patterns_run_map_c</id>
     <text>There is no confirmation inefficient memory access patterns are present. To confirm: Run a &lt;a href=&quot;../help/index.htm#GUID-B98AD81B-4946-4E86-B452-9A1810F4517C.htm&quot;&gt;Memory Access Patterns analysis&lt;/a&gt;. </text>
     <title>Confirm inefficient memory access patterns </title>
     <attributes>
      <float:confidence>2</float:confidence>
     </attributes>
     <parameters>
      <boolean:no_map_disclaimer>true</boolean:no_map_disclaimer>
     </parameters>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>112</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>118</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_system_functions</id>
   <int:severity>1</int:severity>
   <text>System function call(s) in the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;loop body&lt;/a&gt; may prevent the compiler from vectorizing the loop. </text>
   <title>System function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_system_functions_move_c</id>
     <text>Typically system function or subroutine calls cannot be auto-vectorized; even a print statement is sufficient to prevent vectorization. To fix: Avoid using system function calls in loops. </text>
     <title>Remove system function call(s) inside loop </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>122</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_indirect_call</id>
   <int:severity>1</int:severity>
   <text>Indirect function call(s) in the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;loop body&lt;/a&gt; are preventing the compiler from vectorizing the loop. &lt;br&gt; Indirect calls, sometimes called &lt;em&gt;indirect jumps&lt;/em&gt;, get the callee address from a register or memory; direct calls get the callee address from an argument. Even if you force loop vectorization, indirect calls remain serialized. </text>
   <title>Indirect function call(s) present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_indirect_call_move_c</id>
     <text>Indirect function or subroutine calls cannot be vectorized. To fix: Avoid using indirect calls in loops. </text>
     <title>Remove indirect call(s) inside loop </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>122</unsignedLong:rowKey>
  </issue>
 </issues>
 <traits>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>2</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>2</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>3</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>6</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>24</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>25</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>27</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>29</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>29</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>30</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>30</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>31</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>32</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>33</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>38</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>39</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>42</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>44</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>53</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>54</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>59</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>66</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>68</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>70</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>71</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>72</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>72</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>73</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>79</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>81</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>82</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>83</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>84</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>85</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>86</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>91</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>96</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>98</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>103</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>104</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>44</int:fieldId>
   <int:id>2</int:id>
   <text>Irregular Memory Access Patterns May Decrease Performance 
Suggestion: See Recommendations Tab </text>
   <unsignedLong:rowKey>112</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>113</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>117</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>120</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>121</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>121</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>122</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>122</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>123</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>123</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>126</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>127</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>127</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>172</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>175</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>175</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>289</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>289</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>290</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>291</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>291</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>294</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>295</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>295</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>297</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>298</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>299</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>299</unsignedLong:rowKey>
  </trait>
 </traits>
</bag>
